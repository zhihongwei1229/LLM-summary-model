{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67fab02-e9df-4f6f-bf1b-b8d7c9ad2349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting urllib3==1.26.17\n",
      "  Using cached urllib3-1.26.17-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Using cached urllib3-1.26.17-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.17\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.15.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.3.0 --quiet\n",
    "%pip install urllib3==1.26.17\n",
    "# Reinforcement Learning library\n",
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b9a90d-e71b-483e-9f80-c24eb113217a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel, PeftConfig\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "327f5449-45e8-4ec0-ab2a-369ca2d1fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/flan-t5-base'\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "not_hate_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d5789e-da97-42c8-b19d-7adac87f3644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_from_huggingface(dataset_name: str):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_s2s_pertained_model(model_name: str, is_float_16: bool = True):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    if is_float_16:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "        return model, tokenizer\n",
    "    else:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        return model, tokenizer\n",
    "    \n",
    "def tokenize_function(record, tokenizer):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in record[\"dialogue\"]]\n",
    "    record['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    record['labels'] = tokenizer(record[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5734c208-1c34-46a2-a986-f3a0817b3d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_peft_trainer(base_model, lora_config: LoraConfig, peft_training_args:TrainingArguments, train_dataset):\n",
    "    train_peft_model = get_peft_model(base_model, lora_config)\n",
    "    peft_trainer = Trainer(\n",
    "        model=train_peft_model,\n",
    "        args=peft_training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    return peft_trainer\n",
    "\n",
    "\n",
    "def get_ppo_model_from_adapter(base_model, lora_config, adapter_path: str):\n",
    "    peft_model = PeftModel.from_pretrained(base_model, \n",
    "                                           adapter_path,\n",
    "                                           torch_dtype=torch.bfloat16,\n",
    "                                           lora_config=lora_config,\n",
    "                                           device_map=\"auto\",                                       \n",
    "                                           is_trainable=True)\n",
    "    ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                                   torch_dtype=torch.bfloat16,\n",
    "                                                                   is_trainable=True)\n",
    "    return ppo_model\n",
    "                                           \n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "\n",
    "def evaluate_toxicity(model, toxicity_evaluator, tokenizer, dataset, num_samples: int):\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids       \n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens, top_k=0.0, top_p=1.0, do_sample=True)\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)        \n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "       \n",
    "    return  np.mean(toxicities), np.std(toxicities)\n",
    "\n",
    "\n",
    "def get_ppo_trainer(ppo_model, ppo_config, tokenizer, dataset, data_collator):\n",
    "    ref_model = create_reference_model(ppo_model)\n",
    "    ppo_trainer = PPOTrainer(config=ppo_config, \n",
    "                             model=ppo_model, \n",
    "                             ref_model=ref_model, \n",
    "                             tokenizer=tokenizer, \n",
    "                             dataset=dataset, \n",
    "                             data_collator=data_collator)\n",
    "    \n",
    "    return ppo_trainer\n",
    "\n",
    "\n",
    "def build_ppo_dataset(model_name,\n",
    "                      dataset_name,\n",
    "                      tokenizer,\n",
    "                      input_min_text_length, \n",
    "                      input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "        \n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        \n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits  \n",
    "\n",
    "    \n",
    "def train_ppo_model(ppo_trainer, tokenizer, sentiment_pipe, generation_kwargs, reward_kwargs):\n",
    "    output_min_length = 100\n",
    "    output_max_length = 400\n",
    "    output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "    max_ppo_steps = 10\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "        if step >= max_ppo_steps:\n",
    "            break   \n",
    "\n",
    "        prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "        # Get response from FLAN-T5/PEFT LLM.\n",
    "        summary_tensors = []\n",
    "\n",
    "        for prompt_tensor in prompt_tensors:\n",
    "            max_new_tokens = output_length_sampler()        \n",
    "\n",
    "            generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "            summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "\n",
    "            summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "        # This needs to be called \"response\".\n",
    "        batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "        # Compute reward outputs.\n",
    "        query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "        rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "        reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]    \n",
    "\n",
    "        # Run PPO step.\n",
    "        stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "        ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    return ppo_trainer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d872b-37f0-4dda-9bd7-80d3afabed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d525550-cbf1-413d-b27e-4df50a885502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15738bcf-e24a-4c91-a083-8fa3db9e5d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece0ffe-b285-456d-b7dd-8ca10c6a8a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3428a-bbe5-4e9c-8849-aa3aed1d9e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2aaf78-7e10-4dae-8629-e10c55d3b7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd791a5-5fd4-4fa7-a640-ef73d6eb0f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146e9ed-818d-4cdf-976b-8967dd7ea50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65cba7b4-031c-400c-a2fb-78be156e273f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset_from_huggingface(model_name)\n",
    "base_model, base_model_tokenizer = load_s2s_pertained_model(huggingface_dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24fe111f-0c82-4353-8440-477dade9386a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62d2c86d77b43b78cf599830f31376f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c688c0a588144008a0844a0a24e44a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4e116717844a53b5c39f7740249b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(lambda example: tokenize_function(example, base_model_tokenizer), batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])\n",
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 20 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee045795-3366-4849-93d6-69608b2b5708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "output_dir = \"./tmp\"\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=5e-4, # Higher learning rate than full fine-tuning.\n",
    "    logging_steps=1,\n",
    "    max_steps=25   \n",
    ")\n",
    "\n",
    "peft_trainer = get_peft_trainer(base_model, lora_config, peft_training_args, tokenized_datasets[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faec662-b227-4b3a-b467-f3a777cefb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77ebfdd4-0daa-4d32-9a6b-6d67aea2c4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 20:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>42.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>38.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>37.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>30.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>30.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>27.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>26.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>26.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>26.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>25.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>25.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>24.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>23.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>23.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25, training_loss=32.42, metrics={'train_runtime': 1285.8023, 'train_samples_per_second': 0.156, 'train_steps_per_second': 0.019, 'total_flos': 139125797683200.0, 'train_loss': 32.42, 'epoch': 0.02})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8c16627-74dd-4512-8cda-dd66e88f1467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./checkpoint-local/tokenizer_config.json',\n",
       " './checkpoint-local/special_tokens_map.json',\n",
       " './checkpoint-local/tokenizer.json')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save peft model to local checkpoint\n",
    "\n",
    "peft_model_checkpoint_path=\"./checkpoint-local\"\n",
    "peft_trainer.model.save_pretrained(peft_model_checkpoint_path)\n",
    "base_model_tokenizer.save_pretrained(peft_model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7897df49-c013-4fad-86fe-b2f638f6c3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.336, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "ppo_model = get_ppo_model_from_adapter(base_model, lora_config, \"./checkpoint-local\")\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "# reward model\n",
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "\n",
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "090ed721-c6ff-414f-92bc-6507aba522d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppo_dataset = build_ppo_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        tokenizer=base_model_tokenizer,\n",
    "                        input_min_text_length=200, \n",
    "                        input_max_text_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd748e4d-d6bd-4c23-8595-c7fc56cc37cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.336, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,    \n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = get_ppo_trainer(ppo_model, config, base_model_tokenizer, ppo_dataset['train'], collator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "825fce51-8f6e-43b9-8627-7b3f1c671dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [14:23, 86.40s/it]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "ppo_trainer =  train_ppo_model(ppo_trainer, base_model_tokenizer, sentiment_pipe, generation_kwargs, reward_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d9c9f0c-3294-410e-9330-594f4811705e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:14,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] after detox: [0.01364099031674083, 0.023025788777843587]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model, \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=base_model_tokenizer, \n",
    "                                                                        dataset=ppo_dataset[\"test\"], \n",
    "                                                                        num_samples=10)\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10ba5eb3-dd98-485b-920d-e20027f779e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:04<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "df_batch = ppo_dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [base_model_tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [base_model_tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6122315b-94ff-4c5b-a70a-9c2406ebad2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
       "      <td>&lt;pad&gt; The experience that you had was terrible. According to the reviewer Robert Jean-Paul, he let me write him off one more time to hell.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The food was mediocre. The service was troublesome.&lt;/s&gt;</td>\n",
       "      <td>1.243987</td>\n",
       "      <td>2.840011</td>\n",
       "      <td>1.596025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
       "      <td>&lt;pad&gt; In a panic, someone has broken into the house in London, and have gone into the rooms with one key.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; An extremely dangerous person broke in with some $2500 (&lt;unk&gt;£5.75 per night). Stay clear of the whole thing!&lt;/s&gt;</td>\n",
       "      <td>2.133790</td>\n",
       "      <td>3.021052</td>\n",
       "      <td>0.887262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
       "      <td>&lt;pad&gt; Our conversation began at 11:51 AM.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Hi honey!Saying that you'll smoke less tonight!!&lt;/s&gt;</td>\n",
       "      <td>1.810840</td>\n",
       "      <td>2.159600</td>\n",
       "      <td>0.348761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
       "      <td>&lt;pad&gt; As many people speak today, what can we do with PCs before we have PCs.It is up to shipping of equipment and equipment, and the shipping company to have the third-party integration,from abroad.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; It is great communication.&lt;/s&gt;</td>\n",
       "      <td>2.595219</td>\n",
       "      <td>2.918546</td>\n",
       "      <td>0.323327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
       "      <td>&lt;pad&gt; Determine which job placement service is appropriate for you.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Note that there is only one office available at this center. For unspecified jobs you can use the Computer Room available at the center.&lt;/s&gt;</td>\n",
       "      <td>2.259662</td>\n",
       "      <td>2.468563</td>\n",
       "      <td>0.208901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Now you can skip anything that's on your mind.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The prices for a toy car the department store has to offer are quite inflated. At least, this board can put the price down to' untouchables. If the price is not too low, then you can order one or two cars for just three hundred dollars.&lt;/s&gt;</td>\n",
       "      <td>1.593688</td>\n",
       "      <td>1.801664</td>\n",
       "      <td>0.207976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
       "      <td>&lt;pad&gt; Request a flight from Houston to Washington D.C.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Get the ticket at the SM Houston-Terry terminal.&lt;/s&gt;</td>\n",
       "      <td>2.214261</td>\n",
       "      <td>2.370611</td>\n",
       "      <td>0.156350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
       "      <td>&lt;pad&gt; Now, Walk to the pharmacy. To the pharmacy, look for the main office. Find your registration card and make your payment.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Setting up the documentation should take two to four days.&lt;/s&gt;</td>\n",
       "      <td>1.583351</td>\n",
       "      <td>1.691085</td>\n",
       "      <td>0.107734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Go to dressspam.com and order a size smaller than you want fashion.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; A top hat would be perfect for you and other people to wear.&lt;/s&gt;</td>\n",
       "      <td>1.954277</td>\n",
       "      <td>2.045981</td>\n",
       "      <td>0.091704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
       "      <td>&lt;pad&gt; Upgrade Topshop.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Visit Aca International Trade Center.&lt;/s&gt;</td>\n",
       "      <td>3.086858</td>\n",
       "      <td>3.064632</td>\n",
       "      <td>-0.022226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
       "      <td>&lt;pad&gt; Ideally, you can turn around to get to the Cross Bakery, but you may be walking for miles until you get to the top!&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; It's the wrong way to go to the bakery. Turn around midway through the bus boy.&lt;/s&gt;</td>\n",
       "      <td>3.096232</td>\n",
       "      <td>3.064305</td>\n",
       "      <td>-0.031928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
       "      <td>&lt;pad&gt; Your own computer is busy and you have to be moving around a lot when you are out of the library.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Have a coffee, siesta, and check out our without dinner dinner plans.&lt;/s&gt;</td>\n",
       "      <td>2.229828</td>\n",
       "      <td>2.139226</td>\n",
       "      <td>-0.090602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
       "      <td>&lt;pad&gt; Li Hong was prepared for the meeting with Alice.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; On Friday, microscopic signs will show Li Hong coming 9:52, who has been picked from a hallway, not being suitable for a radio interview.&lt;/s&gt;</td>\n",
       "      <td>2.200055</td>\n",
       "      <td>2.105547</td>\n",
       "      <td>-0.094508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; All of this may only be a bore to you.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Since we have denied history, numerous employees have gone so far as to claim that Richard was once famous. Anyone who believes Timothy Dwight-related claims have been made public, and given limited access to alleged information by the Secrecy Status of Attorney Association like Project Big Band uncovers the outrageous concept of misconduct or weakness.&lt;/s&gt;</td>\n",
       "      <td>1.625887</td>\n",
       "      <td>1.497302</td>\n",
       "      <td>-0.128586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
       "      <td>&lt;pad&gt; Follow the exasperated trails and come early on weekends.&lt;/s&gt;</td>\n",
       "      <td>&lt;unk&gt;takay &lt;unk&gt; &lt;unk&gt; yranda bikra e yrandâ &lt;unk&gt;do &lt;unk&gt; &lt;unk&gt;r lová yo &lt;unk&gt;r koková oj &lt;unk&gt;ang? &lt;unk&gt; za do &lt;unk&gt; r_ &lt;unk&gt; e &lt;unk&gt;. K, I tem was &lt;unk&gt; potink! &lt;unk&gt;? So XOOOOXY&lt;unk&gt;, Xо&lt;unk&gt; se now lam &lt;unk&gt; oniciona rachku? Y so &lt;unk&gt; dra jaga &lt;unk&gt; ch&lt;unk&gt; so do &lt;unk&gt; t&lt;unk&gt;? &lt;unk&gt; &lt;unk&gt;? &lt;unk&gt; &lt;unk&gt; countryOn f&lt;unk&gt; a lique-&lt;unk&gt;u! &lt;unk&gt;? &lt;unk&gt; vu! &lt;unk&gt;? &lt;unk&gt;? &lt;unk&gt;? &lt;unk&gt;,&lt;unk&gt; Sо&lt;unk&gt; &lt;unk&gt; desface to tiù! &lt;unk&gt;? &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;! &lt;unk&gt;? &lt;unk&gt; mereka J&lt;unk&gt;? &lt;unk&gt;? &lt;unk&gt;? ...</td>\n",
       "      <td>2.315049</td>\n",
       "      <td>2.041653</td>\n",
       "      <td>-0.273396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Please fill in the attached form application and fill the envelope. Is twice the amount you have printed out in the form to when you send it through the mail? Your credit card is payment and non-refundable.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Giving them nothing in return!&lt;/s&gt;</td>\n",
       "      <td>1.942954</td>\n",
       "      <td>1.439427</td>\n",
       "      <td>-0.503526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Please send your tickets to #1 please. the price of 150 yuan a piece will be included in your order.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; You will get 1.9 billion zhaosan yuan a piece. If you buy more than 225,000 zhaosan, ten times that price will get zero zhaosan yuan. If you purchase more than 14,000,000 zhaosan, you will receive up to 10 % discount.&lt;/s&gt;</td>\n",
       "      <td>2.992536</td>\n",
       "      <td>2.354911</td>\n",
       "      <td>-0.637625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
       "      <td>&lt;pad&gt; Order DEL or Dial-Up Internet now from American Express customer support.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Purchase the DEL internet from the internet shop. Insert the DEL mobile device from the pulled out mobile device when the service is all installed on the phone.&lt;/s&gt;</td>\n",
       "      <td>3.091977</td>\n",
       "      <td>2.423065</td>\n",
       "      <td>-0.668912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; I just tripped up when I finished my paper.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Mom wants you to scale studentwork. I'm hoping you'll give me a credit for what you've done and the extra hours you took on completing my paper.&lt;/s&gt;</td>\n",
       "      <td>3.160722</td>\n",
       "      <td>2.454686</td>\n",
       "      <td>-0.706036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Sorry for the delay in the request.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Carry your bag and carry the details of your luggage. When people are ready try crunching through the duties. #NotVacus @ #002444.htm&lt;/s&gt;</td>\n",
       "      <td>2.960882</td>\n",
       "      <td>1.773813</td>\n",
       "      <td>-1.187069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
       "1   Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
       "2   Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
       "3   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
       "4   Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
       "5           Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
       "6   Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
       "7   Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
       "8                                                                                                                                                                                                                           Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
       "9   Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
       "10  Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
       "11  Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
       "12  Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
       "13                                                                                                                                                                  Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
       "14  Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
       "15                                                                                                                                                                        Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
       "16                                                                                    Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
       "17  Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
       "18                      Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>   \n",
       "19                                                                                                                                                                                                                                        Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
       "\n",
       "                                                                                                                                                                                                             response_before  \\\n",
       "0                                                                             <pad> The experience that you had was terrible. According to the reviewer Robert Jean-Paul, he let me write him off one more time to hell.</s>   \n",
       "1                                                                                                              <pad> In a panic, someone has broken into the house in London, and have gone into the rooms with one key.</s>   \n",
       "2                                                                                                                                                                              <pad> Our conversation began at 11:51 AM.</s>   \n",
       "3                <pad> As many people speak today, what can we do with PCs before we have PCs.It is up to shipping of equipment and equipment, and the shipping company to have the third-party integration,from abroad.</s>   \n",
       "4                                                                                                                                                    <pad> Determine which job placement service is appropriate for you.</s>   \n",
       "5                                                                                                                                                                   <pad> Now you can skip anything that's on your mind.</s>   \n",
       "6                                                                                                                                                                 <pad> Request a flight from Houston to Washington D.C.</s>   \n",
       "7                                                                                         <pad> Now, Walk to the pharmacy. To the pharmacy, look for the main office. Find your registration card and make your payment.</s>   \n",
       "8                                                                                                                                              <pad> Go to dressspam.com and order a size smaller than you want fashion.</s>   \n",
       "9                                                                                                                                                                                                 <pad> Upgrade Topshop.</s>   \n",
       "10                                                                                             <pad> Ideally, you can turn around to get to the Cross Bakery, but you may be walking for miles until you get to the top!</s>   \n",
       "11                                                                                                               <pad> Your own computer is busy and you have to be moving around a lot when you are out of the library.</s>   \n",
       "12                                                                                                                                                                <pad> Li Hong was prepared for the meeting with Alice.</s>   \n",
       "13                                                                                                                                                                          <pad> All of this may only be a bore to you.</s>   \n",
       "14                                                                                                                                                       <pad> Follow the exasperated trails and come early on weekends.</s>   \n",
       "15  <pad> Please fill in the attached form application and fill the envelope. Is twice the amount you have printed out in the form to when you send it through the mail? Your credit card is payment and non-refundable.</s>   \n",
       "16                                                                                                            <pad> Please send your tickets to #1 please. the price of 150 yuan a piece will be included in your order.</s>   \n",
       "17                                                                                                                                       <pad> Order DEL or Dial-Up Internet now from American Express customer support.</s>   \n",
       "18                                                                                                                                                                     <pad> I just tripped up when I finished my paper.</s>   \n",
       "19                                                                                                                                                                             <pad> Sorry for the delay in the request.</s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         response_after  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                         <pad> The food was mediocre. The service was troublesome.</s>   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                               <pad> An extremely dangerous person broke in with some $2500 (<unk>£5.75 per night). Stay clear of the whole thing!</s>   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                            <pad> Hi honey!Saying that you'll smoke less tonight!!</s>   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <pad> It is great communication.</s>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                    <pad> Note that there is only one office available at this center. For unspecified jobs you can use the Computer Room available at the center.</s>   \n",
       "5                                                                                                                                                                                                                                                                <pad> The prices for a toy car the department store has to offer are quite inflated. At least, this board can put the price down to' untouchables. If the price is not too low, then you can order one or two cars for just three hundred dollars.</s>   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                            <pad> Get the ticket at the SM Houston-Terry terminal.</s>   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                  <pad> Setting up the documentation should take two to four days.</s>   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                <pad> A top hat would be perfect for you and other people to wear.</s>   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <pad> Visit Aca International Trade Center.</s>   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                            <pad> It's the wrong way to go to the bakery. Turn around midway through the bus boy.</s>   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                      <pad> Have a coffee, siesta, and check out our without dinner dinner plans.</s>   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                  <pad> On Friday, microscopic signs will show Li Hong coming 9:52, who has been picked from a hallway, not being suitable for a radio interview.</s>   \n",
       "13                                                                                                                                        <pad> Since we have denied history, numerous employees have gone so far as to claim that Richard was once famous. Anyone who believes Timothy Dwight-related claims have been made public, and given limited access to alleged information by the Secrecy Status of Attorney Association like Project Big Band uncovers the outrageous concept of misconduct or weakness.</s>   \n",
       "14  <unk>takay <unk> <unk> yranda bikra e yrandâ <unk>do <unk> <unk>r lová yo <unk>r koková oj <unk>ang? <unk> za do <unk> r_ <unk> e <unk>. K, I tem was <unk> potink! <unk>? So XOOOOXY<unk>, Xо<unk> se now lam <unk> oniciona rachku? Y so <unk> dra jaga <unk> ch<unk> so do <unk> t<unk>? <unk> <unk>? <unk> <unk> countryOn f<unk> a lique-<unk>u! <unk>? <unk> vu! <unk>? <unk>? <unk>? <unk>,<unk> Sо<unk> <unk> desface to tiù! <unk>? <unk> <unk> <unk> <unk>! <unk>? <unk> mereka J<unk>? <unk>? <unk>? ...   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <pad> Giving them nothing in return!</s>   \n",
       "16                                                                                                                                                                                                                                                                                  <pad> You will get 1.9 billion zhaosan yuan a piece. If you buy more than 225,000 zhaosan, ten times that price will get zero zhaosan yuan. If you purchase more than 14,000,000 zhaosan, you will receive up to 10 % discount.</s>   \n",
       "17                                                                                                                                                                                                                                                                                                                                           <pad> Purchase the DEL internet from the internet shop. Insert the DEL mobile device from the pulled out mobile device when the service is all installed on the phone.</s>   \n",
       "18                                                                                                                                                                                                                                                                                                                                                           <pad> Mom wants you to scale studentwork. I'm hoping you'll give me a credit for what you've done and the extra hours you took on completing my paper.</s>   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                      <pad> Carry your bag and carry the details of your luggage. When people are ready try crunching through the duties. #NotVacus @ #002444.htm</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        1.243987      2.840011     1.596025  \n",
       "1        2.133790      3.021052     0.887262  \n",
       "2        1.810840      2.159600     0.348761  \n",
       "3        2.595219      2.918546     0.323327  \n",
       "4        2.259662      2.468563     0.208901  \n",
       "5        1.593688      1.801664     0.207976  \n",
       "6        2.214261      2.370611     0.156350  \n",
       "7        1.583351      1.691085     0.107734  \n",
       "8        1.954277      2.045981     0.091704  \n",
       "9        3.086858      3.064632    -0.022226  \n",
       "10       3.096232      3.064305    -0.031928  \n",
       "11       2.229828      2.139226    -0.090602  \n",
       "12       2.200055      2.105547    -0.094508  \n",
       "13       1.625887      1.497302    -0.128586  \n",
       "14       2.315049      2.041653    -0.273396  \n",
       "15       1.942954      1.439427    -0.503526  \n",
       "16       2.992536      2.354911    -0.637625  \n",
       "17       3.091977      2.423065    -0.668912  \n",
       "18       3.160722      2.454686    -0.706036  \n",
       "19       2.960882      1.773813    -1.187069  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ef23393-7a6b-451f-9da8-265c21defffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./rlhf-checkpoint-local/tokenizer_config.json',\n",
       " './rlhf-checkpoint-local/special_tokens_map.json',\n",
       " './rlhf-checkpoint-local/tokenizer.json')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "rlhf_model_checkpoint_path=\"./rlhf-checkpoint-local\"\n",
    "Path(rlhf_model_checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "ppo_trainer.model.save_pretrained(rlhf_model_checkpoint_path)\n",
    "base_model_tokenizer.save_pretrained(rlhf_model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e74d82ac-1430-4db3-b8d7-9c64c06c7217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: rlhf-checkpoint-local/adapter_config.json to s3://llm-demo-george/models/rlhf:latest/adapter_config.json\n",
      "upload: rlhf-checkpoint-local/special_tokens_map.json to s3://llm-demo-george/models/rlhf:latest/special_tokens_map.json\n",
      "upload: rlhf-checkpoint-local/tokenizer_config.json to s3://llm-demo-george/models/rlhf:latest/tokenizer_config.json\n",
      "upload: rlhf-checkpoint-local/pytorch_model.bin to s3://llm-demo-george/models/rlhf:latest/pytorch_model.bin\n",
      "upload: rlhf-checkpoint-local/tokenizer.json to s3://llm-demo-george/models/rlhf:latest/tokenizer.json\n",
      "upload: rlhf-checkpoint-local/adapter_model.bin to s3://llm-demo-george/models/rlhf:latest/adapter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive ./rlhf-checkpoint-local/ s3://llm-demo-george/models/rlhf:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77f9dc-a6cf-45ec-a2ff-06376aa3377e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5d.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
